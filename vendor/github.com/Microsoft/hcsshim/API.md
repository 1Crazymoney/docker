﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿**Container**Interface describing a container.Methods:- Start- Terminate- Wait- WaitTimeout- Pause- Resume- Statistics- ProcessList- CreateProcess- OpenProcess- Close- Modify- SchemaVersion- CreateProcessEx- @@DebugLCOWGCS- ID- MappedVirtualDisks (v1 only)- HasPendingUpdates (Deprecated)**CreateContainerEx**Creates a container. This is the preferred method rather than the legacy `CreateContainer` API. Supported on RS1 and later.- RS1..RS4: Makes legacy `v1` schema calls into HCS- RS5: Makes `v2` schema calls into HCS`CreateContainerEx(createOptions *CreateOptions) (Container, error)`**CreateOptions**- `ID`. Optional ID for the container. Defaults to random GUID if omitted.- `Owner`. Optional owner for the container. Defaults to executable name if omitted.- `Spec`. OCI specification for the container or utility VM being created - `SchemaVersion`. Schema version object. Defaults to v1 for RS1..4, v2 for RS5- `HostingSystem`. Optional Container object representing a utility VM in which the container should be created.- `AsHostingSystem`. Indicates that the create request is for a utility VM to host containers, or for use as service VM.- `KirdPath`. LCOW. Folder in which kernel and initrd reside. Defaults to \Program Files\Linux Containers.- `KernelFile`. LCOW. Filename under KirdPath for the kernel. Defaults to bootx64.efi.- `InitRdFile`. LCOW. Filename under KirdPath for the initrd image. Defaults to initrd.img.- `KernelBootOptions`. LCOW. Additional boot options for the kernel.-----------**SCSI Functions**`func AddSCSI(uvm Container, hostPath string, containerPath string) (int, int, error)`>This adds a SCSI disk to a utility VM. It supports both v1 and v2 schema, based on the schema the utility VM was created with. hostPath is required. If containerPath is omitted, the disk is only attached to the utility VM on the SCSI bus, and not exposed in a directory. >In the v1 schema, this cannot be used for WCOW as it is not possible to create a WCOW utility VM without a container. (Actually, this may not entirely be true once a container is running in a utility VM, but I haven't tested this). >In the v1 schema for LCOW, a maximum of 62 disks can be added as LUNs 0:0 and 0:1 are reserved for the utility VM scratch and a container scratch.> In the v2 schema for WCOW, a maximum of 63 disks can be added. Current RS5 builds do not support multiple SCSI controllers. This limitation may be fixed, but hcsshim also currently blocks spilling over to a second SCSI controller. `func RemoveSCSI(uvm Container, hostPath string) error`> This removes a SCSI disk from a utility VM. It supports both v1 and v2 schema, based on the schema the utility VM was created with. Both uvm and hostPath are required.**VSMB Functions**VSMB shares are ref-counted. Shares are only added the first time AddVSMB is called, and using those flags. Flags for subsequent adds are ignored.`func AddVSMB(uvm Container, path string, flags int32) error`> This adds the host path to a utility VM as a VSMB share. Only valid for v2 schema-created utility VMs.>> Flags are defined in schemav2.go (`const VsmbFlag*`)`func RemoveVSMB(uvm Container, path string) error`>This removes a VSMB share from a utility VM. Only valid for v2 schema-created utility VMs.`func GetVSMBGUID(uvm Container, path string) (string, error)`> This obtains the VSMB share GUID for a mounted host folder path, as required by a combined layers request.Note: In V2 WCOW Xenons, bind-mounts are VSMB shares to the utility VM, and exposed onwards to the container. The bind-mount is automatically added to the utility VM through the `CreateContainerEx` function. *It is the responsibility of the client to remove.***ContainerLayer Functions**`func MountContainerLayers(layerFolders []string, hostingSystem Container) (interface{}, error)`> This mounts a containers storage on the current host if `hostingSystem` is not supplied, or in the hosting system if supplied. Mounting means each of the read-only layer folders are mounted read-only, a sandbox is mounted read-write and the storage filter driver is loaded exposing the "union" filesystem at a directory.> If hostingSystem is supplied, it must have been created through the v2 schema. > For v1, it returns a volume path such as `\\?\Volume{184575c7-4588-482b-b06b-2dc57ed1f4cf}`> For v2, it returns a `CombinedLayersV2` object where `ContainerRootPath` is the directory in the utility VM where the file system is exposed, and layers describing a populated `ContainerResourcesLayerV2` structure.`func  UnmountContainerLayers(layerFolders []string, hostingSystem Container, op UnmountOperation) error`> This unmounts a containers storage from the current host if `hostingSystem` is not supplied, or from the hosting system if supplied.> If unmounting from the host, the only operation supported is `UnmountOperationAll`.> If hostingSystem is supplied, it must have been created through the v2 schema.> unmounting from a v2 hosting system can be one of two operations - the SCSI attached read/write container sandbox (`UnmountOperationSCSI`) which unloads the filter driver before perfoming a hot-remove, or the VSMB-attached read-only layer folders (`UnmountOperationVSMB`). For file-system consistency in the sandbox, it should always be cleanly removed before terminating a utility VM. It is up to the management stack to determine if the RO layers should be removed before terminating. -----------**EXAMPLES**This section explains the parameters required on create calls for the various types of containers and schema versions.**ALL**Spec.Windows.LayerFolders is required on all calls.  For historical reasons, the (non-intuitive) ordering is: Top most read-only layer folder; other read-only layers; Base layer; Sandbox. For example, consider an image built from microsoft/windowsservercore:1709 with a single additional read-only layer where foo.txt has been added. The order would be (index 0..3)- Additional read-only layer with foo.txt- Servicing layer for the 1709 image (eg 10.0.16299.371 as at April 2018)- Base or "RTM" layer for the 1709 image - Read-Write sandbox layer**v1 Argon** (RS1 or later)- `HCSOPTION_SCHEMA_VERSION` SchemaV10().String(). Required on RS5 as will default to V2. Optional on RS1..RS4- `Spec.Windows.Root`. Optional. If supplied, is a volume GUID of a path where the storage filter driver is loaded. If omitted, the storage will be mounted using `LayerFolders`, and it is the responsibility of the caller to unmount.Examples: `TestV1Argon`, `TestV1ArgonAutoMount`, `TestV1ArgonMultipleBaseLayersAutoMount`**v2 Argon** (RS5 or later)- `Spec.Windows.Root`. Optional. If supplied, is a volume GUID of a path where the storage filter driver is loaded. If omitted, the storage will be mounted using `LayerFolders`, and it is the responsibility of the caller to unmount.Examples: `TestV2Argon`, `TestV2ArgonAutoMountMultipleBaseLayers`, `TestV2ArgonMultipleBaseLayers`**v1 Xenon WCOW** (RS1 or later)Notes:- HCS will handle the lifetime of the utility VM and mount/unmount the containers storage. No API controls are available- Memory sizing of the utility VM is through an algorithm internal to HCS. No API controls are available.- `HCSOPTION_SCHEMA_VERSION` SchemaV10().String(). Required on RS5 as will default to V2. Optional on RS1..RS4- `Spec.Windows.HyperV`. Must be non-nil- `Spec.Windows.HyperV.UtilityVMPath`. Optional. Folder containing the UtilityVM image. Note this is the `UtilityVM` folder, not `UtilityVM\Files` as required by the v2 schema. The helper function `LocateWCOWUVMFolderFromLayerFolders` can be useful to obtain the folders base.Examples: `TestV1XenonWCOW`, `TestV1XenonWCOWNoUVMPath`, `TestV1XenonMultipleBaseLayersNoUVMPath`**v2 Xenon WCOW** (RS5 or later)In the v2 schema, it is the responsibility of the caller to create and manage the lifetime of the utility VM. Some steps are optional from the client perspective and can be automatically performed. *Utility VM** The sandbox folder (passed at the top-most layer folder) will be created if it does not exist* sandbox.vhdx will be automatically created based on the locating the top-most (serviced) read-only layer in the set of layer folders based on SystemTemplate.vhdx, and permissions will be set based on the utility VM ID.* Even if sandbox.vhdx exists in the sandbox folder, it will be overwritten. - `HCSOPTION_SCHEMA_VERSION` SchemaV20().String(). Required.- `HCSOPTION_IS_UTILITY_VM`. Must be a non-empty string. e.g. "yes"- `Spec.Windows.Resources.CPU.Count`. Optional. Defaults to 2 unless on a single LP machine.- `Spec.Windows.Resources.Memory.Limit`. Optional. Defaults to 1GB.For CPU and memory resources, the helper function `UVMResourcesFromContainerSpec` is useful to mirror functionality built into HCS in the v1 APIs. Generally this is only useful when sizing a utility VM knowing that a single container is going to be started in it.*Container*- `HCSOPTION_SCHEMA_VERSION` SchemaV20().String(). Required.- `HCSOPTION_COMBINED_LAYERS` ajskdlfjakslNote:- Multiple containers can be created inside the utility VM.- The containers storage is automatically mounted in the utility VM unless `HCSOPTION_COMBINED_LAYERS` is passed.- The caller is responsible for unmounting the storage from the utility VM.- hcsshim does reference counting on the storage- A maximum of 64 SCSI attachments are supported by the platform, thus this limits the maximum number of read-only layers and hence containers in a single utility VM to 64. (Actually, think this is 63 as the UVM scratch is mounted on SCSI). Stefan hopes to fix this for RTM, code in hcsshim can cope with 4x64, but there's a block in hcsshim currently when falls over to the second SCSI controller.Examples:  `TestV2XenonWCOW`, `TestV2XenonWCOWTwoContainers`, `TestV2XenonWCOWCreateLots`